{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1a44b9a-abe7-47f9-b4db-13c3de814532",
   "metadata": {},
   "source": [
    "# Introduction to Parallel Programming\n",
    "\n",
    "This notebook shows how to write, compile, and run parallel program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d3d5b7-8b09-48d0-90b7-32e15b797cb6",
   "metadata": {},
   "source": [
    "## Shared Memory Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad21bcd6-cadc-43ad-ad04-ea6c72ba1a89",
   "metadata": {},
   "source": [
    "Here’s a simple \"Hello World\" program using OpenMP in C. OpenMP is an API that supports multi-platform shared memory multiprocessing programming in C, C++, and Fortran.\n",
    "\n",
    "Example OpenMP Program: `openmp_hello_world.c`\n",
    "\n",
    "```\n",
    "#include <stdio.h>\n",
    "#include <omp.h>\n",
    "#include <unistd.h>  // for gethostname\n",
    "#include <limits.h>  // for HOST_NAME_MAX\n",
    "\n",
    "int main() {\n",
    "    // Variable to store the hostname\n",
    "    char hostname[HOST_NAME_MAX];\n",
    "    \n",
    "    // Get the hostname of the machine\n",
    "    gethostname(hostname, HOST_NAME_MAX);\n",
    "\n",
    "    // Set number of threads\n",
    "    omp_set_num_threads(4);\n",
    "    \n",
    "    // Parallel region starts here\n",
    "    #pragma omp parallel\n",
    "    {\n",
    "        // Each thread will execute this code block\n",
    "        int thread_id = omp_get_thread_num();\n",
    "        int num_threads = omp_get_num_threads();\n",
    "        \n",
    "        printf(\"Hello World from thread %d out of %d threads running on %s\\n\", thread_id, num_threads, hostname);\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "- `#pragma omp parallel`: This directive tells the compiler to parallelize the following block of code. Each thread will execute the code inside this block.\n",
    "- `omp_get_thread_num()`: This function returns the ID of the current thread, which ranges from 0 to num_threads-1.\n",
    "- `omp_get_num_threads()`: This function returns the total number of threads in the parallel region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a635da81-3e07-4106-b5b4-d12094eb298b",
   "metadata": {},
   "source": [
    "**1. Compile the Program:**\n",
    "\n",
    "To compile an OpenMP program, you need to use the `-fopenmp` flag with gcc:\n",
    "\n",
    "```$ gcc -fopenmp -o hello_world/openmp_hello_world.exe hello_world/openmp_hello_world.c```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e135740-c129-49c7-b080-1dc23afe0414",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc -fopenmp -o hello_world/openmp_hello_world.exe hello_world/openmp_hello_world.c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c45a49-1d0c-4271-a4dc-ebfd8718962f",
   "metadata": {},
   "source": [
    "**2. Run the Program:**\n",
    "\n",
    "Run the compiled program:\n",
    "\n",
    "```$ ./hello_world/openmp_hello_world.exe```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed6ef0ae-54ab-4a31-96dd-a2e14b9d6894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World from thread 1 out of 4 threads running on grid1\n",
      "Hello World from thread 3 out of 4 threads running on grid1\n",
      "Hello World from thread 2 out of 4 threads running on grid1\n",
      "Hello World from thread 0 out of 4 threads running on grid1\n"
     ]
    }
   ],
   "source": [
    "!./hello_world/openmp_hello_world.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57c1642-8982-438b-a71a-60b282187503",
   "metadata": {},
   "source": [
    "## Distributed Memory Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da53b09-49bc-435b-93d9-e3dcd7eafdb7",
   "metadata": {},
   "source": [
    "Here’s a simple \"Hello World\" program using MPI in C. MPI is a library that supports multi-node distributed memory parallelism programming in C, C++, and Fortran.\n",
    "\n",
    "Example MPI Program: `mpi_hello_world.c`\n",
    "\n",
    "```\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "#include <unistd.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(NULL, NULL);\n",
    "    \n",
    "    int world_size;\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n",
    "    \n",
    "    int world_rank;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n",
    "    \n",
    "    char hostname[256];\n",
    "    gethostname(hostname, sizeof(hostname));\n",
    "\n",
    "    printf(\"Hello world from rank %d out of %d processors running on %s\\n\", world_rank, world_size, hostname);\n",
    "    \n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c50f9ee-c775-4a5c-8ddb-2010d712e521",
   "metadata": {},
   "source": [
    "**1. Compile the Program:**\n",
    "\n",
    "To compile an MPI program, you need to use the mpicc:\n",
    "\n",
    "```$ mpicc -o mpi_hello_world mpi_hello_world.c```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0240bce1-5143-47d4-a68e-34e23dd2114b",
   "metadata": {},
   "source": [
    "**2. Run the Program:**\n",
    "\n",
    "To run an MPI program, you need to use the mpirun. But you need to define nodes and number of slot (processors) that can be used in MPI program.\n",
    "\n",
    "Example `hostfile`\n",
    "\n",
    "```\n",
    "grid1 slots=2\n",
    "grid2 slots=2\n",
    "```\n",
    "\n",
    "Thus, you can execute the MPI program by defining hostfile and the number of processor (that should be less than total number of slots in hostfile.\n",
    "\n",
    "```$ mpirun -np 4 -hostfile hostfile mpi_hello_world```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d108801-3482-4692-94a3-42883bd29dbd",
   "metadata": {},
   "source": [
    "Unfortunately, the xeus-cling kernel is designed for interactive C++ programming and doesn't have built-in support for MPI compilation. The MPI program have to be compiled and run outside of the xeus-cling kernel. This means you won't get interactive output as you would with regular C++ code in xeus-cling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55426b4c-4b91-4ff7-9599-8fc918b62026",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++17",
   "language": "C++17",
   "name": "xcpp17"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
